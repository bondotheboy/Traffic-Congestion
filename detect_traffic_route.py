# -*- coding: utf-8 -*-
"""Detect Traffic Route.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P5Uw5ufQL3k321DNeI66fPVrs1ENn9SU
"""

import cv2
import math
import csv
from collections import defaultdict, deque
from ultralytics import YOLO
import numpy as np
import streamlit as st

"""#Replacing and using Bytetrack"""

def traffic_congestion_detection(video,model,frame_placeholder):


# Configuration
CLASSES_TO_TRACK = ["car", "motorcycle", "bus", "truck"]
TRAJECTORY_RANGES = {
    "West to East": (-80, 0),
    "North to South": (10, 160),
    "East to West": (160, 180),
    "South to North": (-180, -50),
}
FRAME_WINDOW_SIZE = 30
VIDEO_PATH = video  # Set your input video file path
OUTPUT_VIDEO_PATH = 'annotated_output.mp4'
OUTPUT_CSV = 'vehicle_tracking.csv'
THROUGHPUT_CSV = 'route_throughput.csv'
default_throughput={
    "West to East": 0,
    "North to South": 0,
    "East to West": 0,
    "South to North": 0,
}

# Initialize YOLOv11 model
model = YOLO('model')  # Ensure yolov11.pt is accessible

# Data structures
vehicle_tracks = defaultdict(lambda: deque(maxlen=FRAME_WINDOW_SIZE))
route_vehicle_counts = {
    "North to South": {"all_vehicles": [], "car": [], "motorcycle": [], "bus": [], "truck": [], "active_frame_count": []},
    "East to West": {"all_vehicles": [], "car": [], "motorcycle": [], "bus": [], "truck": [], "active_frame_count": []},
    "South to North": {"all_vehicles": [], "car": [], "motorcycle": [], "bus": [], "truck": [], "active_frame_count": []},
    "West to East": {"all_vehicles": [], "car": [], "motorcycle": [], "bus": [], "truck": [], "active_frame_count": []},
}
csv_data = []
traffic_throughput_data = []

def calculate_theta(x1, y1, x2, y2):
    dx = x2 - x1
    dy = y2 - y1
    theta = math.degrees(math.atan2(dy, dx))
    return theta

def calculate_distance(x1, y1, x2, y2):
    return math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)

def classify_route(theta, displacement):
    for route, (min_theta, max_theta) in TRAJECTORY_RANGES.items():
        if min_theta <= theta <= max_theta and displacement >= 25:
            return route
    return "Unknown"

def add_vehicle_id(route, class_name, vehicle_id):
    """
    Adds vehicle_id to the respective class list if it doesn't exist yet.
    """
    if class_name in route_vehicle_counts[route]:
        if vehicle_id not in route_vehicle_counts[route][class_name]:
            route_vehicle_counts[route][class_name].append(vehicle_id)



# Open video
cap = cv2.VideoCapture(VIDEO_PATH)
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
fps = cap.get(cv2.CAP_PROP_FPS)
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

def calculate_route_throughput(frame_num,route):
  if frame_num%125 == 0: # check traffic throughput every 5 seconds
    if len(route_vehicle_counts[route]['active_frame_count'])>=250: # check for the past 10 seconds in a specfic route
      start_frame=route_vehicle_counts[route]['active_frame_count'][-250]
      start_frame_ids = list({entry['id'] for entry in csv_data if entry['frame'] == start_frame}) #What are the unique vehicles in the first frame of the 10 sec window
      all_vehicle_ids = route_vehicle_counts[route]['all_vehicles']
      for sid in start_frame_ids:
        if sid in all_vehicle_ids:
            idx = all_vehicle_ids.index(sid)
            vehicle_count = len(all_vehicle_ids[idx:])
            traffic_throughput_data.append({'frame': frame_num, 'route': route, 'vehicle_count': vehicle_count})
            return vehicle_count
    else: return 0
  else:
    return 0



# Prepare video writer
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(OUTPUT_VIDEO_PATH, fourcc, fps, (width, height))

frame_num = 0

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    frame_num += 1

    # Add check for frame limit
    #if frame_num > 500:
        #break

    # Run YOLO detection
    results = model.track(frame, persist=True, tracker="bytetrack.yaml")[0]  # Assuming the first index holds detections

    current_frame_routes = defaultdict(int)

    for result in results.boxes:
        x_min, y_min, x_max, y_max = result.xyxy[0].tolist()
        class_id = int(result.cls[0])
        class_name = model.names[class_id]

        if class_name not in CLASSES_TO_TRACK:
            continue

        # Get track ID from tracker
        track_id = int(result.id[0]) if result.id is not None else -1
        vehicle_id = f"{class_name}_{track_id}"

        # Calculate centroid
        cx = int((x_min + x_max) / 2)
        cy = int((y_min + y_max) / 2)

        #vehicle_id = f"{int(class_id)}_{int(cx)}_{int(cy)}"

        # Append centroid to track
        vehicle_tracks[vehicle_id].append((cx, cy, x_min, y_min, x_max, y_max))

        # Once enough frames are accumulated, calculate trajectory
        if len(vehicle_tracks[vehicle_id]) >= FRAME_WINDOW_SIZE:
            start = vehicle_tracks[vehicle_id][0]
            end = vehicle_tracks[vehicle_id][-1]
            theta = calculate_theta(start[0], start[1], end[0], end[1])
            displacement = calculate_distance(start[0], start[1], end[0], end[1]) # Modified this line
            print(f"vehicle {vehicle_id} has more than 30 frames and displacement {displacement} theta {theta}")
            route = classify_route(theta,displacement)

            if route != "Unknown":
                current_frame_routes[route] += 1
                add_vehicle_id(route, class_name, vehicle_id)
                add_vehicle_id(route, "all_vehicles", vehicle_id)



            # Draw bounding box and label with calculated theta
            #cv2.rectangle(frame, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 2)
        #else:
             # Draw bounding box and label with "TBC" or similar for initial frames
        cv2.rectangle(frame, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 2)
        cv2.putText(frame, f"{class_name}", (cx, cy - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)


        # Save data for CSV
        csv_data.append({
            'frame': frame_num,
            'total_frames': total_frames,
            'class': class_name,
            'id': vehicle_id,
            'cx': cx,
            'cy': cy
        })


    # Determine active route
    active_route = max(current_frame_routes, key=current_frame_routes.get, default="None")
    if active_route != "None":
      add_vehicle_id(active_route, "active_frame_count", frame_num)
    #cv2.rectangle(frame, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 1)
    #cv2.putText(frame, f"{class_name}", (cx, cy - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

    # Draw overlay table
    overlay_text = f"Current Signal: {active_route}\n"
    overlay_text += "Total Vehicles On Routes:\n"
    for route, counts in route_vehicle_counts.items():
        car_count = len(counts["car"])
        motorcycle_count = len(counts["motorcycle"])
        bus_count = len(counts["bus"])
        truck_count = len(counts["truck"])
        total_unique_frames = len(counts["active_frame_count"])

        total_vehicles = car_count + motorcycle_count + bus_count + truck_count
        throughput = calculate_route_throughput(frame_num,route)

        if throughput:
          default_throughput[route] = throughput
        else:
          throughput = default_throughput[route]

        overlay_text += (
            f"{route}: {total_vehicles} | "
            f"C={car_count}, M={motorcycle_count}, B={bus_count}, T={truck_count} | "
            f"Throughput={throughput}\n"
        )
    #for route, counts in route_vehicle_counts.items():
        #overlay_text += f"{route}: {'|'.join(map(str, counts))}\n"

    y0, dy = 30, 25
    for i, line in enumerate(overlay_text.strip().split('\n')):
        y = y0 + i * dy
        cv2.putText(frame, line, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 0), 1)


    # Save annotated frame to video
    #out.write(frame)
    rgb_frame = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)

    # Display in Streamlit
    frame_placeholder.image(rgb_frame, channels="RGB", use_column_width=True)

    # Optional: display frame in real time (can be disabled in Colab)
    # cv2.imshow('Annotated Traffic', frame)
    # if cv2.waitKey(1) & 0xFF == ord('q'):
    #     break

# Cleanup
cap.release()
#out.release()
# cv2.destroyAllWindows()

# Save CSV
with open(OUTPUT_CSV, 'w', newline='') as f:
    writer = csv.DictWriter(f, fieldnames=['frame', 'total_frames', 'class', 'id', 'cx', 'cy'])
    writer.writeheader()
    writer.writerows(csv_data)
# Save throughput data
with open(THROUGHPUT_CSV, 'w', newline='') as f:
    writer = csv.DictWriter(f, fieldnames=['frame', 'route', 'vehicle_count'])
    writer.writeheader()
    writer.writerows(traffic_throughput_data)

print(f"Annotated video saved as: {OUTPUT_VIDEO_PATH}")
print(f"Vehicle tracking CSV saved as: {OUTPUT_CSV}")



